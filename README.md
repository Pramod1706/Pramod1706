Got it! Below is the optimized high-speed setup with 1 Logstash, 1 Filebeat, 1 Kibana, and 3 Elasticsearch Pods, ensuring fast ingestion, indexing, and search performance for your 200GB historical + 20GB daily logs.


---

ğŸš€ Optimized Resource Allocation for Maximum Speed


---

ğŸ”¥ Key Performance Optimizations

1ï¸âƒ£ 3 Elasticsearch Pods as Master + Data

Balanced cluster, high availability, and fast indexing


2ï¸âƒ£ Optimized Elasticsearch Heap

-Xms4g -Xmx4g (50% of 8GB RAM per pod)


3ï¸âƒ£ Fast Log Ingestion with Logstash

Batch Size: 1000 â†’ More logs processed per cycle

Batch Delay: 10ms â†’ Lower delay for real-time logs

Persistent Queue: Enabled â†’ Prevents log loss


4ï¸âƒ£ Filebeat Tweaks for Faster Log Shipping

Bulk Max Size: 2000 â†’ Sends larger batches to Logstash

Queue Flush Timeout: 5s â†’ Reduces latency


5ï¸âƒ£ SSD Storage (At Least 1TB)

Ensures fast I/O for indexing & searches



---

âš¡ Performance Metrics with This Setup


---

ğŸ“Œ When to Scale Further?

If logs exceed 30GB/day or users increase beyond 300, consider:
âœ… Increasing Logstash batch size to 1500
âœ… Increasing Elasticsearch heap to 6GB (-Xms6g -Xmx6g)
âœ… Adding 1 more Elasticsearch pod for better distribution


---

This setup ensures high-speed log ingestion, real-time search, and smooth dashboard performance with minimal pod usage. Let me know if you need fine-tuning! ğŸš€

